# 下一步行动计划

**当前状态**: ✅ 已完成10-seed实验 + bug修复 + 分析报告
**当前问题**: ❌ 统计不显著 (t=1.516 < 2.045) + 6个失败案例
**目标**: 🎯 修复失败案例，达到统计显著性 (p<0.05)

---

## 📋 立即行动清单（按优先级）

### 第1步：运行诊断脚本 ⭐⭐⭐⭐⭐

**目的**: 找出Seed 2027 Medium崩溃的根本原因

**操作**:
```bash
# 在您的main分支运行
cd F:\simulation3

# 运行诊断脚本（会自动对比seed 2027 vs 2026）
python scripts/diagnose_failure_cases.py
```

**预计时间**: 5-10分钟（运行2次实验）

**输出**:
- 屏幕上显示详细对比分析
- 生成文件: `diagnostic_report_seed2027.json`

**您将看到**:
1. ✅ 算子使用对比（哪些算子被过度/不足使用）
2. ✅ Q-values对比（是否有异常值）
3. ✅ 状态转换对比（是否过早进入stuck）
4. ✅ 具体修复建议

---

### 第2步：分析诊断结果 ⭐⭐⭐⭐⭐

**根据诊断脚本的输出，检查以下关键点**:

#### 关键检查点A：算子失衡？

查找输出中的 "算子使用对比" 部分：

```
算子使用对比
--------------------------------------------------------------------------------
算子                            成功案例        失败案例        差异
--------------------------------------------------------------------------------
lp_repair                      20.0% ( 10)    5.0% (  3)    -15.0% ⚠️ 差异大
random_removal                 30.0% ( 15)    70.0% ( 35)   +40.0% ⚠️ 差异大
```

**症状**: 如果某个算子在失败案例中占比>60%，说明严重失衡

**原因**: Q-learning学习到了错误的策略，过度使用劣质算子

**修复**: 增加探索率，避免过早收敛

---

#### 关键检查点B：Q-values异常？

查找输出中的 "Q-values对比" 部分：

```
State: normal
  算子                            成功案例 Q      失败案例 Q      差异
--------------------------------------------------------------------------------
  lp_repair                         5.234         -2.156      -7.390 ⚠️
  random_removal                   -1.234         10.234     +11.468 ⚠️
```

**症状**:
- Q值差异>5.0说明学习方向完全相反
- Q值出现NaN或>100的极端值

**原因**:
- Reward scaling不当
- 学习率过大导致过度更新

**修复**: 调整learning_rate或reward_scaling

---

#### 关键检查点C：过早进入stuck？

查找输出中的 "状态转换历史" 部分：

```
状态转换历史:
--------------------------------------------------------------------------------
  1. Iteration 8: normal -> stuck        ⚠️ 过早
  2. Iteration 15: stuck -> deep_stuck
```

**症状**: 如果在<10次迭代就进入stuck，说明阈值设置不当

**原因**: `stagnation_threshold` 对Medium规模过于严格

**修复**: 增大stagnation_threshold

---

### 第3步：根据诊断应用修复 ⭐⭐⭐⭐⭐

**根据诊断结果，选择对应的修复方案**:

---

#### 修复方案A：增加探索率（针对算子失衡）

**文件**: `src/planner/q_learning.py`

**修改位置**: 找到epsilon相关参数

**原代码**:
```python
self.epsilon = 1.0
self.epsilon_min = 0.01
self.epsilon_decay = 0.995
```

**修改为**:
```python
self.epsilon = 1.0
self.epsilon_min = 0.1  # 从0.01改为0.1，保持10%探索
self.epsilon_decay = 0.995
```

**理由**: 保持更多探索，避免过早收敛到次优策略

---

#### 修复方案B：调整stagnation阈值（针对过早stuck）

**文件**: `src/planner/alns.py`

**修改位置**: 找到stagnation_threshold定义

**原代码**:
```python
if not_improved_count >= 10:  # stagnation_threshold
    self.state = 'stuck'
```

**修改为**:
```python
# 根据规模调整阈值
threshold_by_scale = {
    'small': 10,
    'medium': 15,  # Medium规模需要更宽松
    'large': 20
}
# 或者简单地统一改为15
if not_improved_count >= 15:
    self.state = 'stuck'
```

**理由**: Medium规模问题更复杂，需要更多迭代才能判断是否陷入停滞

---

#### 修复方案C：调整学习率（针对Q-values异常）

**文件**: `src/planner/q_learning.py`

**修改位置**: 找到learning_rate定义

**原代码**:
```python
self.learning_rate = 0.5
```

**修改为**:
```python
self.learning_rate = 0.1  # 降低学习率，避免过度更新
```

**理由**: 降低学习率可以让Q-values更平滑地收敛，避免剧烈波动

---

#### 修复方案D：组合修复（推荐）

如果诊断发现**多个问题同时存在**，建议组合应用：

```python
# src/planner/q_learning.py
self.epsilon_min = 0.1          # 修复A：增加探索
self.learning_rate = 0.1        # 修复C：降低学习率

# src/planner/alns.py
stagnation_threshold = 15       # 修复B：放宽stuck阈值
```

---

### 第4步：验证修复效果 ⭐⭐⭐⭐

**应用修复后，重新运行失败案例**:

```bash
# 测试Seed 2027 Medium
python scripts/generate_alns_visualization.py --seed 2027

# 检查结果
# 目标: Medium规模Q-learning改进率从17.01%提升到>35%
```

**成功标准**:
- ✅ Seed 2027 Medium: 从17.01%提升到>35%
- ✅ 其他seeds不受负面影响
- ✅ 算子使用更均衡（无单一算子>60%）

---

### 第5步：重新运行完整10-seed测试 ⭐⭐⭐⭐

**修复验证通过后，运行完整测试**:

```bash
# 运行所有10个seeds（耗时较长，可分批运行）
for seed in 2025 2026 2027 2028 2029 2030 2031 2032 2033 2034
do
    echo "Running seed $seed..."
    python scripts/generate_alns_visualization.py --seed $seed
done
```

**或者使用已有的批量脚本**（如果您有）

---

### 第6步：重新计算统计显著性 ⭐⭐⭐

**运行分析脚本**:

```bash
python scripts/analyze_10seeds_results.py
```

**检查输出中的统计检验结果**:

```
统计显著性检验:
  Mean difference:     +X.XX%
  t-statistic:         X.XXX

  ✅ 统计显著 at α=0.05 (|t| = X.XXX > 2.045)
  或
  ❌ 不显著 at α=0.05 (|t| = X.XXX < 2.045)
```

**成功标准**:
- ✅ t > 2.045 (达到统计显著)
- ✅ 平均差异 > 5%
- ✅ 无崩溃级失败案例（gap<15%）

---

## 🔄 如果修复不成功怎么办？

### 情况1：Seed 2027仍然失败

**原因**: 可能不是参数问题，而是算法设计问题

**下一步**:
1. 重复运行Seed 2027 Medium 5-10次
2. 如果每次都失败 → 这是算法局限性，需要在论文中讨论
3. 如果偶尔成功 → 这是随机初始化问题，可以通过改进初始化解决

---

### 情况2：修复了2027但破坏了其他seeds

**原因**: 参数调整过度，不具有泛化性

**下一步**:
1. 使用更保守的参数调整
2. 考虑自适应参数（根据规模动态调整）
3. 运行参数敏感性分析

---

### 情况3：仍然无法达到统计显著

**原因**: 算法本身优势不够明显

**下一步**:
1. 执行**消融实验**（对比Random、Roulette）
2. 重新评估论文定位（可能不强调"优于Matheuristic"，而强调"自适应学习"）
3. 考虑Tier 2期刊或会议论文

---

## 📊 时间线估计

| 步骤 | 预计时间 | 累计时间 |
|:-----|:--------:|:--------:|
| 第1步: 运行诊断 | 10分钟 | 10分钟 |
| 第2步: 分析结果 | 30分钟 | 40分钟 |
| 第3步: 应用修复 | 1小时 | 1.5小时 |
| 第4步: 验证修复 | 30分钟 | 2小时 |
| 第5步: 完整测试 | 2-3小时 | 4-5小时 |
| 第6步: 统计分析 | 10分钟 | 5小时 |

**预计总耗时**: 半个工作日

---

## ✅ 成功检查清单

在进入下一阶段（消融实验）之前，确保：

- [ ] Seed 2027 Medium改进率 > 35%
- [ ] Seed 2031 Large改进率 > 25%
- [ ] 无崩溃级失败案例（所有cases gap < 15%）
- [ ] t统计量 > 2.045
- [ ] 平均差异 > 5%
- [ ] Large规模CV < 25%

---

## 🚀 立即开始

**现在就运行**:

```bash
cd F:\simulation3
python scripts/diagnose_failure_cases.py
```

等待诊断完成后，查看输出并决定使用哪个修复方案。

**有任何疑问或需要帮助**:
- 运行诊断脚本后，分享输出给我
- 我可以帮您解读结果，确定最佳修复方案
- 如果遇到错误，立即告诉我

---

**祝诊断顺利！** 🎯

找到问题根源后，修复就会变得简单。保持耐心，我们一定能解决这个问题！
