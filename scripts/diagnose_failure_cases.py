#!/usr/bin/env python3
"""
è¯Šæ–­è„šæœ¬ï¼šå¯¹æ¯”æˆåŠŸä¸å¤±è´¥æ¡ˆä¾‹ï¼Œæ‰¾å‡ºQ-learningå¤±è´¥çš„æ ¹æœ¬åŸå› 

ä¸“é—¨åˆ†æï¼š
- Seed 2027 Medium (å¤±è´¥: 17.01%)  vs  Seed 2026 Medium (æˆåŠŸ: 53.56%)
- Seed 2031 Large (å¤±è´¥: 8.34%)    vs  Seed 2026 Large (æˆåŠŸ: 38.31%)
"""

import sys
import os
import json
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from data.instance_generator import generate_test_instance
from planner.alns import MinimalALNS
from tests.optimization.common import run_q_learning_trial
import random


def diagnose_single_case(seed: int, scale: str, iterations: int = 50):
    """è¿è¡Œå•ä¸ªæ¡ˆä¾‹å¹¶æ”¶é›†è¯Šæ–­ä¿¡æ¯"""

    print(f"\n{'='*80}")
    print(f"è¯Šæ–­æ¡ˆä¾‹: Seed {seed}, Scale {scale}")
    print(f"{'='*80}\n")

    # è®¾ç½®éšæœºç§å­
    random.seed(seed)

    # ç”Ÿæˆé—®é¢˜å®ä¾‹
    scale_config = {
        'small': {'num_tasks': 10, 'num_stations': 1},
        'medium': {'num_tasks': 20, 'num_stations': 2},
        'large': {'num_tasks': 30, 'num_stations': 3}
    }

    config = scale_config[scale]
    distance_matrix, task_pool, charging_stations, vehicle_template = generate_test_instance(
        num_tasks=config['num_tasks'],
        num_charging_stations=config['num_stations'],
        seed=seed
    )

    # è¿è¡Œbaseline
    baseline_alns = MinimalALNS(
        distance_matrix=distance_matrix,
        task_pool=task_pool,
        charging_stations=charging_stations,
        repair_mode='greedy',
        use_adaptive=False
    )
    baseline = baseline_alns.generate_initial_solution(vehicle_template)
    baseline_cost = baseline_alns.evaluate(baseline)

    print(f"Baseline cost: {baseline_cost:.2f}")

    # åˆ›å»ºALNSå®ä¾‹ï¼Œå¯ç”¨è¯¦ç»†æ—¥å¿—
    alns = MinimalALNS(
        distance_matrix=distance_matrix,
        task_pool=task_pool,
        charging_stations=charging_stations,
        repair_mode='adaptive',
        use_adaptive=True,
        verbose=True  # å¯ç”¨è¯¦ç»†è¾“å‡º
    )

    # æ”¶é›†è¯Šæ–­ä¿¡æ¯
    diagnostics = {
        'seed': seed,
        'scale': scale,
        'baseline_cost': baseline_cost,
        'iterations': iterations,
        'operator_selections': {},
        'state_transitions': [],
        'q_values_samples': [],
        'improvements': []
    }

    # è¿è¡Œä¼˜åŒ–å¹¶ç›‘æ§
    print(f"\nå¼€å§‹ä¼˜åŒ– (è¿­ä»£æ¬¡æ•°: {iterations})...")
    print("-" * 80)

    try:
        # è¿è¡ŒQ-learningä¼˜åŒ–
        optimised = alns.optimize(baseline, max_iterations=iterations)
        optimised_cost = alns.evaluate(optimised)
        improvement = (baseline_cost - optimised_cost) / baseline_cost * 100

        diagnostics['optimised_cost'] = optimised_cost
        diagnostics['improvement'] = improvement

        print(f"\nä¼˜åŒ–å®Œæˆ!")
        print(f"Optimised cost: {optimised_cost:.2f}")
        print(f"Improvement: {improvement:.2f}%")

        # å¦‚æœALNSæœ‰Q-learning agentï¼Œè·å–å…¶ç»Ÿè®¡ä¿¡æ¯
        if hasattr(alns, '_q_agent') and alns._q_agent is not None:
            q_agent = alns._q_agent

            # è·å–ç®—å­ä½¿ç”¨ç»Ÿè®¡
            if hasattr(q_agent, 'action_counts'):
                diagnostics['operator_selections'] = dict(q_agent.action_counts)

                print(f"\nç®—å­ä½¿ç”¨ç»Ÿè®¡:")
                print("-" * 80)
                total_selections = sum(q_agent.action_counts.values())
                for action, count in sorted(q_agent.action_counts.items(), key=lambda x: x[1], reverse=True):
                    percentage = count / total_selections * 100
                    print(f"  {action}: {count} æ¬¡ ({percentage:.1f}%)")

            # è·å–Q-tableæ ·æœ¬
            if hasattr(q_agent, 'q_table'):
                q_table_sample = {}
                for state in ['normal', 'stuck', 'deep_stuck']:
                    if state in q_agent.q_table:
                        q_table_sample[state] = dict(q_agent.q_table[state])
                diagnostics['q_values_samples'] = q_table_sample

                print(f"\nQ-valuesæ ·æœ¬ (å½“å‰çŠ¶æ€):")
                print("-" * 80)
                for state, values in q_table_sample.items():
                    print(f"  State: {state}")
                    for action, q_val in sorted(values.items(), key=lambda x: x[1], reverse=True):
                        print(f"    {action}: {q_val:.3f}")

        # æ£€æŸ¥çŠ¶æ€è½¬æ¢å†å²ï¼ˆå¦‚æœæœ‰è®°å½•ï¼‰
        if hasattr(alns, 'state_history'):
            diagnostics['state_transitions'] = alns.state_history

            print(f"\nçŠ¶æ€è½¬æ¢å†å²:")
            print("-" * 80)
            for i, state_change in enumerate(alns.state_history):
                print(f"  {i+1}. Iteration {state_change['iteration']}: {state_change['from']} -> {state_change['to']}")

    except Exception as e:
        print(f"\nâŒ ä¼˜åŒ–è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        diagnostics['error'] = str(e)

    return diagnostics


def compare_cases(success_diag, failure_diag):
    """å¯¹æ¯”æˆåŠŸå’Œå¤±è´¥æ¡ˆä¾‹ï¼Œæ‰¾å‡ºå…³é”®å·®å¼‚"""

    print(f"\n\n{'='*80}")
    print(f"å¯¹æ¯”åˆ†æ: æˆåŠŸ vs å¤±è´¥")
    print(f"{'='*80}\n")

    print(f"æˆåŠŸæ¡ˆä¾‹: Seed {success_diag['seed']} {success_diag['scale']}")
    print(f"  æ”¹è¿›ç‡: {success_diag.get('improvement', 0):.2f}%")

    print(f"\nå¤±è´¥æ¡ˆä¾‹: Seed {failure_diag['seed']} {failure_diag['scale']}")
    print(f"  æ”¹è¿›ç‡: {failure_diag.get('improvement', 0):.2f}%")

    print(f"\nå·®è·: {success_diag.get('improvement', 0) - failure_diag.get('improvement', 0):.2f}%")

    # å¯¹æ¯”ç®—å­ä½¿ç”¨
    print(f"\n\n1. ç®—å­ä½¿ç”¨å¯¹æ¯”")
    print("-" * 80)

    success_ops = success_diag.get('operator_selections', {})
    failure_ops = failure_diag.get('operator_selections', {})

    all_operators = set(success_ops.keys()) | set(failure_ops.keys())

    print(f"{'ç®—å­':<30} {'æˆåŠŸæ¡ˆä¾‹':<15} {'å¤±è´¥æ¡ˆä¾‹':<15} {'å·®å¼‚':<15}")
    print("-" * 80)

    for op in sorted(all_operators):
        success_count = success_ops.get(op, 0)
        failure_count = failure_ops.get(op, 0)

        success_total = sum(success_ops.values()) if success_ops else 1
        failure_total = sum(failure_ops.values()) if failure_ops else 1

        success_pct = success_count / success_total * 100
        failure_pct = failure_count / failure_total * 100

        diff = failure_pct - success_pct

        marker = ""
        if abs(diff) > 15:
            marker = "âš ï¸ å·®å¼‚å¤§"

        print(f"{op:<30} {success_pct:>6.1f}% ({success_count:>3}) {failure_pct:>6.1f}% ({failure_count:>3}) {diff:>+6.1f}% {marker}")

    # å¯¹æ¯”Q-values
    print(f"\n\n2. Q-valueså¯¹æ¯”")
    print("-" * 80)

    success_q = success_diag.get('q_values_samples', {})
    failure_q = failure_diag.get('q_values_samples', {})

    for state in ['normal', 'stuck', 'deep_stuck']:
        if state in success_q or state in failure_q:
            print(f"\nState: {state}")
            print(f"  {'ç®—å­':<30} {'æˆåŠŸæ¡ˆä¾‹ Q':<15} {'å¤±è´¥æ¡ˆä¾‹ Q':<15} {'å·®å¼‚':<15}")
            print("-" * 80)

            success_state_q = success_q.get(state, {})
            failure_state_q = failure_q.get(state, {})

            all_actions = set(success_state_q.keys()) | set(failure_state_q.keys())

            for action in sorted(all_actions):
                success_val = success_state_q.get(action, 0.0)
                failure_val = failure_state_q.get(action, 0.0)
                diff = failure_val - success_val

                marker = ""
                if abs(diff) > 1.0:
                    marker = "âš ï¸"

                print(f"  {action:<30} {success_val:>10.3f} {failure_val:>10.3f} {diff:>+10.3f} {marker}")

    # è¯Šæ–­ç»“è®º
    print(f"\n\n3. è¯Šæ–­ç»“è®º")
    print("=" * 80)

    # æ£€æŸ¥ç®—å­å¤±è¡¡
    if failure_ops:
        failure_total = sum(failure_ops.values())
        for op, count in failure_ops.items():
            pct = count / failure_total * 100
            if pct > 60:
                print(f"âš ï¸  ç®—å­ä¸¥é‡å¤±è¡¡: '{op}' è¢«ä½¿ç”¨äº† {pct:.1f}%")

    # æ£€æŸ¥Q-valueså¼‚å¸¸
    for state, values in failure_q.items():
        for action, q_val in values.items():
            if abs(q_val) > 100:
                print(f"âš ï¸  Q-valueå¼‚å¸¸: state={state}, action={action}, Q={q_val:.3f}")
            if q_val != q_val:  # NaN check
                print(f"âŒ Q-valueä¸ºNaN: state={state}, action={action}")

    # å¯¹æ¯”çŠ¶æ€è½¬æ¢
    success_transitions = success_diag.get('state_transitions', [])
    failure_transitions = failure_diag.get('state_transitions', [])

    if success_transitions and failure_transitions:
        print(f"\nçŠ¶æ€è½¬æ¢å¯¹æ¯”:")
        print(f"  æˆåŠŸæ¡ˆä¾‹: {len(success_transitions)} æ¬¡è½¬æ¢")
        print(f"  å¤±è´¥æ¡ˆä¾‹: {len(failure_transitions)} æ¬¡è½¬æ¢")

        # æ£€æŸ¥æ˜¯å¦è¿‡æ—©è¿›å…¥stuck
        if failure_transitions:
            first_stuck = next((t for t in failure_transitions if 'stuck' in t.get('to', '')), None)
            if first_stuck and first_stuck.get('iteration', 999) < 10:
                print(f"âš ï¸  è¿‡æ—©è¿›å…¥stuckçŠ¶æ€: ç¬¬{first_stuck['iteration']}æ¬¡è¿­ä»£")


def main():
    """ä¸»å‡½æ•°ï¼šè¿è¡Œè¯Šæ–­æµç¨‹"""

    print("="*80)
    print("Q-learningå¤±è´¥æ¡ˆä¾‹è¯Šæ–­å·¥å…·")
    print("="*80)

    # è¯Šæ–­æ¡ˆä¾‹1: Seed 2027 Medium (å¤±è´¥)
    print("\n\nç¬¬ä¸€éƒ¨åˆ†: è¯Šæ–­å¤±è´¥æ¡ˆä¾‹")
    failure_diag_2027 = diagnose_single_case(seed=2027, scale='medium', iterations=50)

    # è¯Šæ–­æ¡ˆä¾‹2: Seed 2026 Medium (æˆåŠŸ)
    print("\n\nç¬¬äºŒéƒ¨åˆ†: è¯Šæ–­æˆåŠŸæ¡ˆä¾‹ï¼ˆå‚ç…§ï¼‰")
    success_diag_2026 = diagnose_single_case(seed=2026, scale='medium', iterations=50)

    # å¯¹æ¯”åˆ†æ
    compare_cases(success_diag_2026, failure_diag_2027)

    # ä¿å­˜è¯Šæ–­æŠ¥å‘Š
    report = {
        'failure_case': failure_diag_2027,
        'success_case': success_diag_2026,
        'timestamp': str(__import__('datetime').datetime.now())
    }

    output_file = Path(__file__).parent.parent / 'diagnostic_report_seed2027.json'
    with open(output_file, 'w') as f:
        json.dump(report, f, indent=2, default=str)

    print(f"\n\nè¯Šæ–­æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")

    # ç”Ÿæˆä¿®å¤å»ºè®®
    print(f"\n\n{'='*80}")
    print(f"ä¿®å¤å»ºè®®")
    print(f"{'='*80}")

    improvement_diff = success_diag_2026.get('improvement', 0) - failure_diag_2027.get('improvement', 0)

    if improvement_diff > 25:
        print(f"\nğŸ”¥ ä¸¥é‡å¤±è´¥ (å·®è· {improvement_diff:.1f}%)")
        print("\nå»ºè®®çš„ä¿®å¤æ–¹å‘:")
        print("  1. æ£€æŸ¥Q-learningå‚æ•°è®¾ç½®ï¼ˆlearning_rate, epsilon_decayï¼‰")
        print("  2. è°ƒæ•´stagnation_thresholdï¼ˆå¯èƒ½å¯¹Mediumè§„æ¨¡ä¸é€‚é…ï¼‰")
        print("  3. å¢åŠ epsilon_minä¿æŒæ¢ç´¢")
        print("  4. æ£€æŸ¥reward_scalingæ˜¯å¦åˆç†")
        print("\nå…·ä½“æ“ä½œ:")
        print("  åœ¨ src/planner/alns.py ä¸­:")
        print("    - stagnation_threshold: ä»å½“å‰å€¼æ”¹ä¸º 15-20")
        print("  åœ¨ src/planner/q_learning.py ä¸­:")
        print("    - epsilon_min: ä» 0.01 æ”¹ä¸º 0.1")
        print("    - learning_rate: å°è¯• 0.1-0.3")

    print("\n\nä¸‹ä¸€æ­¥:")
    print("  1. æŸ¥çœ‹è¯Šæ–­æŠ¥å‘Š: diagnostic_report_seed2027.json")
    print("  2. æ ¹æ®å»ºè®®è°ƒæ•´å‚æ•°")
    print("  3. é‡æ–°è¿è¡Œ: python scripts/generate_alns_visualization.py --seed 2027")
    print("  4. éªŒè¯æ”¹è¿›æ•ˆæœ")


if __name__ == '__main__':
    main()
